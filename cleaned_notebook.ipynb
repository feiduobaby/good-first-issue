{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feiduobaby/good-first-issue/blob/main/cleaned_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr0JSKB8qCmT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Data Prepatation"
      ],
      "metadata": {
        "id": "xzumKaz4E_a2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget $'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv'"
      ],
      "metadata": {
        "id": "jNV-Z7TdqqJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('course_lead_scoring.csv')\n",
        "\n",
        "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "\n",
        "categorical = ['lead_source', 'industry', 'employment_status', 'location']\n",
        "numerical = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
        "\n",
        "for c in categorical:\n",
        "    df[c] = df[c].fillna('NA')\n",
        "\n",
        "for c in numerical:\n",
        "    df[c] = df[c].fillna(0)\n"
      ],
      "metadata": {
        "id": "eB2WBwgHrFop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "pq6KOLuBDDsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
        "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
        "\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_val = df_val.reset_index(drop=True)\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "y_train = df_train.converted.values\n",
        "y_val = df_val.converted.values\n",
        "y_test = df_test.converted.values\n",
        "\n",
        "del df_train['converted']\n",
        "del df_val['converted']\n",
        "del df_test['converted']"
      ],
      "metadata": {
        "id": "P8gG5OOsu0gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "c-J9U6mjC6Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dv = DictVectorizer(sparse=False)\n",
        "\n",
        "train_dict = df_train[categorical + numerical].to_dict(orient='records')\n",
        "X_train = dv.fit_transform(train_dict)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "xMGXwpSlwkj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dict = df_val[categorical + numerical].to_dict(orient='records')\n",
        "X_val = dv.transform(val_dict)\n",
        "\n",
        "y_pred = model.predict_proba(X_val)[:, 1]\n",
        "churn_decision = (y_pred >= 0.5)\n",
        "(y_val == churn_decision).mean()"
      ],
      "metadata": {
        "id": "XlKpE2qBEI0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Accuracy and dummy model"
      ],
      "metadata": {
        "id": "X1IR1QwgE3-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "KIf2nU8NpnNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_val, y_pred >= 0.5)"
      ],
      "metadata": {
        "id": "5HEAI5dfp0SK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = np.linspace(0, 1, 21)\n",
        "\n",
        "scores = []\n",
        "\n",
        "for t in thresholds:\n",
        "    score = accuracy_score(y_val, y_pred >= t)\n",
        "    print('%.2f %.3f' % (t, score))\n",
        "    scores.append(score)"
      ],
      "metadata": {
        "id": "UPPSt7Kvp4dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(thresholds, scores)"
      ],
      "metadata": {
        "id": "l138QZHYp-wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(y_pred >= 1.0)"
      ],
      "metadata": {
        "id": "mfDFsdgPqGAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1 - y_val.mean()"
      ],
      "metadata": {
        "id": "qIZqkEizqJwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Confusion Table"
      ],
      "metadata": {
        "id": "vcFZIkPSrB80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual_positive = (y_val == 1)\n",
        "actual_negative = (y_val == 0)\n",
        "t = 0.5\n",
        "predict_positive = (y_pred >= t)\n",
        "predict_negative = (y_pred < t)\n",
        "tp = (predict_positive & actual_positive).sum()\n",
        "tn = (predict_negative & actual_negative).sum()\n",
        "\n",
        "fp = (predict_positive & actual_negative).sum()\n",
        "fn = (predict_negative & actual_positive).sum()\n",
        "confusion_matrix = np.array([\n",
        "    [tn, fp],\n",
        "    [fn, tp]\n",
        "])\n",
        "confusion_matrix"
      ],
      "metadata": {
        "id": "3-1TZaJWrFpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(confusion_matrix / confusion_matrix.sum()).round(2)"
      ],
      "metadata": {
        "id": "f_CFBtt3rM0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Precision and Recall"
      ],
      "metadata": {
        "id": "BWVYEPjUrS6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = tp / (tp + fp)\n",
        "p"
      ],
      "metadata": {
        "id": "LlWqNNnfFHMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = tp / (tp + fn)\n",
        "r"
      ],
      "metadata": {
        "id": "9ZwV-CbxFPai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 ROC Curves"
      ],
      "metadata": {
        "id": "TcWZKkCpFS1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TPR and FRP"
      ],
      "metadata": {
        "id": "gbrEemw1FVVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tpr = tp / (tp + fn)\n",
        "tpr"
      ],
      "metadata": {
        "id": "I_0QvlFFFY5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr = fp / (fp + tn)\n",
        "fpr"
      ],
      "metadata": {
        "id": "_kgsI2N7FcvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "\n",
        "thresholds = np.linspace(0, 1, 101)\n",
        "\n",
        "for t in thresholds:\n",
        "    actual_positive = (y_val == 1)\n",
        "    actual_negative = (y_val == 0)\n",
        "\n",
        "    predict_positive = (y_pred >= t)\n",
        "    predict_negative = (y_pred < t)\n",
        "\n",
        "    tp = (predict_positive & actual_positive).sum()\n",
        "    tn = (predict_negative & actual_negative).sum()\n",
        "\n",
        "    fp = (predict_positive & actual_negative).sum()\n",
        "    fn = (predict_negative & actual_positive).sum()\n",
        "\n",
        "    scores.append((t, tp, fp, fn, tn))\n",
        "columns = ['threshold', 'tp', 'fp', 'fn', 'tn']\n",
        "df_scores = pd.DataFrame(scores, columns=columns)\n",
        "\n",
        "df_scores['tpr'] = df_scores.tp / (df_scores.tp + df_scores.fn)\n",
        "df_scores['fpr'] = df_scores.fp / (df_scores.fp + df_scores.tn)\n",
        "plt.plot(df_scores.threshold, df_scores['tpr'], label='TPR')\n",
        "plt.plot(df_scores.threshold, df_scores['fpr'], label='FPR')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "2OC0QjoJFfd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random model"
      ],
      "metadata": {
        "id": "Hs8DnyVwFvMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "y_rand = np.random.uniform(0, 1, size=len(y_val))\n",
        "((y_rand >= 0.5) == y_val).mean()"
      ],
      "metadata": {
        "id": "UbZWqKocFx75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tpr_fpr_dataframe(y_val, y_pred):\n",
        "    scores = []\n",
        "\n",
        "    thresholds = np.linspace(0, 1, 101)\n",
        "\n",
        "    for t in thresholds:\n",
        "        actual_positive = (y_val == 1)\n",
        "        actual_negative = (y_val == 0)\n",
        "\n",
        "        predict_positive = (y_pred >= t)\n",
        "        predict_negative = (y_pred < t)\n",
        "\n",
        "        tp = (predict_positive & actual_positive).sum()\n",
        "        tn = (predict_negative & actual_negative).sum()\n",
        "\n",
        "        fp = (predict_positive & actual_negative).sum()\n",
        "        fn = (predict_negative & actual_positive).sum()\n",
        "\n",
        "        scores.append((t, tp, fp, fn, tn))\n",
        "\n",
        "    columns = ['threshold', 'tp', 'fp', 'fn', 'tn']\n",
        "    df_scores = pd.DataFrame(scores, columns=columns)\n",
        "\n",
        "    df_scores['tpr'] = df_scores.tp / (df_scores.tp + df_scores.fn)\n",
        "    df_scores['fpr'] = df_scores.fp / (df_scores.fp + df_scores.tn)\n",
        "\n",
        "    return df_scores"
      ],
      "metadata": {
        "id": "56F451SRF1Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_rand = tpr_fpr_dataframe(y_val, y_rand)\n",
        "plt.plot(df_rand.threshold, df_rand['tpr'], label='TPR')\n",
        "plt.plot(df_rand.threshold, df_rand['fpr'], label='FPR')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "WvhSijWtF-_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ideal model"
      ],
      "metadata": {
        "id": "IsfsngTgF70C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_neg = (y_val == 0).sum()\n",
        "num_pos = (y_val == 1).sum()\n",
        "num_neg, num_pos"
      ],
      "metadata": {
        "id": "vWGchuesGRXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_ideal = np.repeat([0, 1], [num_neg, num_pos])\n",
        "y_ideal\n",
        "\n",
        "y_ideal_pred = np.linspace(0, 1, len(y_val))\n",
        "1 - y_val.mean()"
      ],
      "metadata": {
        "id": "ciu6lpylGS2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_ideal, y_ideal_pred >= 0.726)"
      ],
      "metadata": {
        "id": "Cr_4aoCKGV2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ideal = tpr_fpr_dataframe(y_ideal, y_ideal_pred)\n",
        "df_ideal[::10]"
      ],
      "metadata": {
        "id": "XbI2t4QpGZOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(df_ideal.threshold, df_ideal['tpr'], label='TPR')\n",
        "plt.plot(df_ideal.threshold, df_ideal['fpr'], label='FPR')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "iHvvcFZTGcyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting everything together"
      ],
      "metadata": {
        "id": "OZLbN4hRGh72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(df_scores.threshold, df_scores['tpr'], label='TPR', color='black')\n",
        "plt.plot(df_scores.threshold, df_scores['fpr'], label='FPR', color='blue')\n",
        "\n",
        "plt.plot(df_ideal.threshold, df_ideal['tpr'], label='TPR ideal')\n",
        "plt.plot(df_ideal.threshold, df_ideal['fpr'], label='FPR ideal')\n",
        "\n",
        "# plt.plot(df_rand.threshold, df_rand['tpr'], label='TPR random', color='grey')\n",
        "# plt.plot(df_rand.threshold, df_rand['fpr'], label='FPR random', color='grey')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "ACLqV-FrGjBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5, 5))\n",
        "\n",
        "plt.plot(df_scores.fpr, df_scores.tpr, label='Model')\n",
        "plt.plot([0, 1], [0, 1], label='Random', linestyle='--')\n",
        "\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "a8765QkVGoD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_pred)\n",
        "plt.figure(figsize=(5, 5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='Model')\n",
        "plt.plot([0, 1], [0, 1], label='Random', linestyle='--')\n",
        "\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "KWYojh_gGvkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 ROC AUC"
      ],
      "metadata": {
        "id": "SNp4ZtGAGrlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import auc\n",
        "auc(fpr, tpr)"
      ],
      "metadata": {
        "id": "yERzL63DG3JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc(df_scores.fpr, df_scores.tpr)"
      ],
      "metadata": {
        "id": "xmleL0z9G73w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc(df_ideal.fpr, df_ideal.tpr)"
      ],
      "metadata": {
        "id": "osl_0kkcG-1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_val, y_pred)\n",
        "auc(fpr, tpr)"
      ],
      "metadata": {
        "id": "ns5HhxziHDNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_val, y_pred)"
      ],
      "metadata": {
        "id": "tiftueRcHEif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neg = y_pred[y_val == 0]\n",
        "pos = y_pred[y_val == 1]\n",
        "import random\n",
        "n = 100000\n",
        "success = 0\n",
        "\n",
        "for i in range(n):\n",
        "    pos_ind = random.randint(0, len(pos) - 1)\n",
        "    neg_ind = random.randint(0, len(neg) - 1)\n",
        "\n",
        "    if pos[pos_ind] > neg[neg_ind]:\n",
        "        success = success + 1\n",
        "\n",
        "success / n"
      ],
      "metadata": {
        "id": "k-_B-JjzHHhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 50000\n",
        "\n",
        "np.random.seed(1)\n",
        "pos_ind = np.random.randint(0, len(pos), size=n)\n",
        "neg_ind = np.random.randint(0, len(neg), size=n)\n",
        "\n",
        "(pos[pos_ind] > neg[neg_ind]).mean()"
      ],
      "metadata": {
        "id": "ECUjv47hHNTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 Cross-Validation"
      ],
      "metadata": {
        "id": "QTa_ZkvrHQaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(df_train, y_train, C=1.0):\n",
        "    dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
        "\n",
        "    dv = DictVectorizer(sparse=False)\n",
        "    X_train = dv.fit_transform(dicts)\n",
        "\n",
        "    model = LogisticRegression(C=C, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    return dv, model\n",
        "dv, model = train(df_train, y_train, C=0.001)\n",
        "def predict(df, dv, model):\n",
        "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
        "\n",
        "    X = dv.transform(dicts)\n",
        "    y_pred = model.predict_proba(X)[:, 1]\n",
        "\n",
        "    return y_pred\n",
        "y_pred = predict(df_val, dv, model)\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "tLpuHX7LHSZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "SF4c1RyuHdI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "n_splits = 5\n",
        "\n",
        "for C in tqdm([0.001, 0.01, 0.1, 0.5, 1, 5, 10]):\n",
        "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
        "\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kfold.split(df_full_train):\n",
        "        df_train = df_full_train.iloc[train_idx]\n",
        "        df_val = df_full_train.iloc[val_idx]\n",
        "\n",
        "        y_train = df_train.converted.values\n",
        "        y_val = df_val.converted.values\n",
        "\n",
        "        dv, model = train(df_train, y_train, C=C)\n",
        "        y_pred = predict(df_val, dv, model)\n",
        "\n",
        "        auc = roc_auc_score(y_val, y_pred)\n",
        "        scores.append(auc)\n",
        "\n",
        "    print('C=%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
      ],
      "metadata": {
        "id": "XsE4ALl2HjvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "id": "HgmA9kcvH0Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dv, model = train(df_full_train, df_full_train.converted.values, C=1.0)\n",
        "y_pred = predict(df_test, dv, model)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "auc"
      ],
      "metadata": {
        "id": "ZfSsDSMrH2Kg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}