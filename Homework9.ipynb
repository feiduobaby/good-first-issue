{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhc4hszey4pFZVBUAWtlZ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feiduobaby/good-first-issue/blob/main/Homework9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K695ulUaB751"
      },
      "outputs": [],
      "source": [
        "PREFIX=\"https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle\"\n",
        "DATA_URL=f\"{PREFIX}/hair_classifier_v1.onnx.data\"\n",
        "MODEL_URL=f\"{PREFIX}/hair_classifier_v1.onnx\"\n",
        "!wget $DATA_URL\n",
        "!wget $MODEL_URL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE4eAFQyDk6a",
        "outputId": "fcf70bf8-a93b-43c7-e244-ef1b285aaaa6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "from urllib import request\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def download_image(url):\n",
        "    with request.urlopen(url) as resp:\n",
        "        buffer = resp.read()\n",
        "    stream = BytesIO(buffer)\n",
        "    img = Image.open(stream)\n",
        "    return img\n",
        "\n",
        "\n",
        "def prepare_image(img, target_size):\n",
        "    if img.mode != 'RGB':\n",
        "        img = img.convert('RGB')\n",
        "    img = img.resize(target_size, Image.NEAREST)\n",
        "    return img"
      ],
      "metadata": {
        "id": "oGE_gfTNDp3h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "R-Zuy7OeDrJR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnx"
      ],
      "metadata": {
        "id": "o7pl6olGK-6K",
        "outputId": "669bed29-2184-46dc-ac6b-be710c0370de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n",
            "Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "# Load your ONNX model\n",
        "model = onnx.load(\"/content/hair_classifier_v1.onnx\")\n",
        "\n",
        "# Get the output names\n",
        "output_names = [output.name for output in model.graph.output]\n",
        "\n",
        "print(\"Output names:\", output_names)\n"
      ],
      "metadata": {
        "id": "4Ws2i5--JvUt",
        "outputId": "71028ec7-e24c-43d3-885f-cf4d761c85b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output names: ['output']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg'"
      ],
      "metadata": {
        "id": "l1iSx2680gdY",
        "outputId": "e539fc50-2a27-434f-a948-a3f70360a8de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-04 10:04:45--  https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\n",
            "Resolving habrastorage.org (habrastorage.org)... 95.47.173.34, 95.47.173.35, 2a14:b680:0:56::34, ...\n",
            "Connecting to habrastorage.org (habrastorage.org)|95.47.173.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 398272 (389K) [image/jpeg]\n",
            "Saving to: ‘yf_dokzqy3vcritme8ggnzqlvwa.jpeg’\n",
            "\n",
            "yf_dokzqy3vcritme8g 100%[===================>] 388.94K   807KB/s    in 0.5s    \n",
            "\n",
            "2025-12-04 10:04:47 (807 KB/s) - ‘yf_dokzqy3vcritme8ggnzqlvwa.jpeg’ saved [398272/398272]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = prepare_image(download_image('https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg'),(200,200))"
      ],
      "metadata": {
        "id": "mLXmtquw8Miy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = img_to_array(img)                         # NumPy array, float32 [web:8]\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "x[0,0,0]"
      ],
      "metadata": {
        "id": "ipSCZFUu8gpI",
        "outputId": "eedb8f80-956b-4c05-9948-f61fa4990b4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-81.939   , -12.778999, -62.68    ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "si3xpGJPAI46"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 1) Conv layer: in 3 ch, out 32 ch, kernel 3x3\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3))\n",
        "        # 2) Max pooling: 2x2\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "        # After conv1 (no padding): input (3,200,200) -> (32, 198, 198)\n",
        "        # After maxpool 2x2: -> (32, 99, 99)\n",
        "        # Flatten size = 32 * 99 * 99\n",
        "        self.fc1 = nn.Linear(32 * 99 * 99, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "        self.sigmoid = nn.Sigmoid()  # binary output\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, 3, 200, 200)\n",
        "        x = self.conv1(x)          # (batch, 32, 198, 198)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)           # (batch, 32, 99, 99)\n",
        "        x = torch.flatten(x, 1)    # (batch, 32*99*99)\n",
        "        x = self.fc1(x)            # (batch, 64)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)            # (batch, 1)\n",
        "        x = self.sigmoid(x)        # probability for class 1\n",
        "        return x"
      ],
      "metadata": {
        "id": "OK6COaEKCpBM"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
        "\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "94u3Iu8ACrMl"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "# 1) Define same size, channels-first, and normalization if you want\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),     # model expects 200x200 [web:35]\n",
        "    transforms.ToTensor(),             # -> (C, H, W), values in [0, 1] [web:36]\n",
        "    # Optional: add Normalize(...) here if you trained with it [web:39]\n",
        "])\n",
        "\n",
        "# 2) Load and transform image\n",
        "img = img.convert(\"RGB\")  # 3 channels [web:37]\n",
        "x = transform(img)            # shape (3, 200, 200)\n",
        "x = x.unsqueeze(0)            # shape (1, 3, 200, 200) add batch dim [web:35]"
      ],
      "metadata": {
        "id": "OJSwlo4wDjw9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()\n",
        "model.eval()                                                            # eval mode [web:37]\n",
        "\n",
        "with torch.no_grad():\n",
        "    y = model(x)              # shape (1, 1)\n",
        "    prob = y.item()           # scalar probability for class 1\n",
        "\n",
        "# For binary decision:\n",
        "pred = 1 if prob >= 0.5 else 0\n",
        "print(\"prob:\", prob, \"pred:\", pred)"
      ],
      "metadata": {
        "id": "X7sRELQVESxA",
        "outputId": "630eee17-2799-477b-88f8-661cc8825175",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prob: 0.4599649906158447 pred: 0\n"
          ]
        }
      ]
    }
  ]
}