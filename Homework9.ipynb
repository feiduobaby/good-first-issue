{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYJq5oZZ4yntS+BzbX9aEL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feiduobaby/good-first-issue/blob/main/Homework9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K695ulUaB751",
        "outputId": "6d5386d9-a4d7-4a89-fc1f-fc3f1855814b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-06 12:02:19--  https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/hair_classifier_v1.onnx.data\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/426348925/398ded4a-c41c-4e5a-9672-acb7e441de54?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-06T12%3A39%3A13Z&rscd=attachment%3B+filename%3Dhair_classifier_v1.onnx.data&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-06T11%3A38%3A27Z&ske=2025-12-06T12%3A39%3A13Z&sks=b&skv=2018-11-09&sig=pDoEb1EkhE0ddMrI%2BOe8OsSQy1uwDAcfY8CJRz9REuQ%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NTAyNDM0MCwibmJmIjoxNzY1MDIyNTQwLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.5H67hb-7ch5CiATq17yFEM28Bb0nefaZ0rzWiu906HM&response-content-disposition=attachment%3B%20filename%3Dhair_classifier_v1.onnx.data&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-06 12:02:20--  https://release-assets.githubusercontent.com/github-production-release-asset/426348925/398ded4a-c41c-4e5a-9672-acb7e441de54?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-06T12%3A39%3A13Z&rscd=attachment%3B+filename%3Dhair_classifier_v1.onnx.data&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-06T11%3A38%3A27Z&ske=2025-12-06T12%3A39%3A13Z&sks=b&skv=2018-11-09&sig=pDoEb1EkhE0ddMrI%2BOe8OsSQy1uwDAcfY8CJRz9REuQ%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NTAyNDM0MCwibmJmIjoxNzY1MDIyNTQwLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.5H67hb-7ch5CiATq17yFEM28Bb0nefaZ0rzWiu906HM&response-content-disposition=attachment%3B%20filename%3Dhair_classifier_v1.onnx.data&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 80355328 (77M) [application/octet-stream]\n",
            "Saving to: ‘hair_classifier_v1.onnx.data’\n",
            "\n",
            "hair_classifier_v1. 100%[===================>]  76.63M  58.4MB/s    in 1.3s    \n",
            "\n",
            "2025-12-06 12:02:21 (58.4 MB/s) - ‘hair_classifier_v1.onnx.data’ saved [80355328/80355328]\n",
            "\n",
            "--2025-12-06 12:02:21--  https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/hair_classifier_v1.onnx\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/426348925/c6b83ad5-a901-40e9-bf2c-41ad174c870c?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-06T12%3A58%3A30Z&rscd=attachment%3B+filename%3Dhair_classifier_v1.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-06T11%3A57%3A43Z&ske=2025-12-06T12%3A58%3A30Z&sks=b&skv=2018-11-09&sig=xP1c1Ysh54nu3Zp4yhvOnAL8%2FrGYlvdGZJVQKhvGH6s%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NTAyMjg0MSwibmJmIjoxNzY1MDIyNTQxLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.ZT4kF0FQ6V4EutpR4GRg3lLIcmbN0FhkWgi2qPFS2o8&response-content-disposition=attachment%3B%20filename%3Dhair_classifier_v1.onnx&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-06 12:02:21--  https://release-assets.githubusercontent.com/github-production-release-asset/426348925/c6b83ad5-a901-40e9-bf2c-41ad174c870c?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-06T12%3A58%3A30Z&rscd=attachment%3B+filename%3Dhair_classifier_v1.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-06T11%3A57%3A43Z&ske=2025-12-06T12%3A58%3A30Z&sks=b&skv=2018-11-09&sig=xP1c1Ysh54nu3Zp4yhvOnAL8%2FrGYlvdGZJVQKhvGH6s%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NTAyMjg0MSwibmJmIjoxNzY1MDIyNTQxLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.ZT4kF0FQ6V4EutpR4GRg3lLIcmbN0FhkWgi2qPFS2o8&response-content-disposition=attachment%3B%20filename%3Dhair_classifier_v1.onnx&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10337 (10K) [application/octet-stream]\n",
            "Saving to: ‘hair_classifier_v1.onnx’\n",
            "\n",
            "hair_classifier_v1. 100%[===================>]  10.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-06 12:02:22 (34.8 MB/s) - ‘hair_classifier_v1.onnx’ saved [10337/10337]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "PREFIX=\"https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle\"\n",
        "DATA_URL=f\"{PREFIX}/hair_classifier_v1.onnx.data\"\n",
        "MODEL_URL=f\"{PREFIX}/hair_classifier_v1.onnx\"\n",
        "!wget $DATA_URL\n",
        "!wget $MODEL_URL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE4eAFQyDk6a",
        "outputId": "946adf3a-58e9-4f3c-e41a-749988ce65a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "from urllib import request\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def download_image(url):\n",
        "    with request.urlopen(url) as resp:\n",
        "        buffer = resp.read()\n",
        "    stream = BytesIO(buffer)\n",
        "    img = Image.open(stream)\n",
        "    return img\n",
        "\n",
        "\n",
        "def prepare_image(img, target_size):\n",
        "    if img.mode != 'RGB':\n",
        "        img = img.convert('RGB')\n",
        "    img = img.resize(target_size, Image.NEAREST)\n",
        "    return img"
      ],
      "metadata": {
        "id": "oGE_gfTNDp3h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "R-Zuy7OeDrJR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnx"
      ],
      "metadata": {
        "id": "o7pl6olGK-6K",
        "outputId": "207a0931-cd6a-4a83-b57a-752cfd22d131",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n",
            "Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "# Load your ONNX model\n",
        "model = onnx.load(\"/content/hair_classifier_v1.onnx\")\n",
        "\n",
        "# Get the output names\n",
        "output_names = [output.name for output in model.graph.output]\n",
        "\n",
        "print(\"Output names:\", output_names)\n"
      ],
      "metadata": {
        "id": "4Ws2i5--JvUt",
        "outputId": "3156281a-c3e4-4f61-b8cc-1bcaf1735bca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output names: ['output']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg'"
      ],
      "metadata": {
        "id": "l1iSx2680gdY",
        "outputId": "8e79263a-c429-42c8-87d6-11e9900c1147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-06 12:04:17--  https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\n",
            "Resolving habrastorage.org (habrastorage.org)... 95.47.173.34, 95.47.173.35, 2a14:b680:0:56::35, ...\n",
            "Connecting to habrastorage.org (habrastorage.org)|95.47.173.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 398272 (389K) [image/jpeg]\n",
            "Saving to: ‘yf_dokzqy3vcritme8ggnzqlvwa.jpeg’\n",
            "\n",
            "yf_dokzqy3vcritme8g 100%[===================>] 388.94K   803KB/s    in 0.5s    \n",
            "\n",
            "2025-12-06 12:04:19 (803 KB/s) - ‘yf_dokzqy3vcritme8ggnzqlvwa.jpeg’ saved [398272/398272]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = prepare_image(download_image('https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg'),(200,200))"
      ],
      "metadata": {
        "id": "mLXmtquw8Miy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "si3xpGJPAI46"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 1) Conv layer: in 3 ch, out 32 ch, kernel 3x3\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3))\n",
        "        # 2) Max pooling: 2x2\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "        # After conv1 (no padding): input (3,200,200) -> (32, 198, 198)\n",
        "        # After maxpool 2x2: -> (32, 99, 99)\n",
        "        # Flatten size = 32 * 99 * 99\n",
        "        self.fc1 = nn.Linear(32 * 99 * 99, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "        self.sigmoid = nn.Sigmoid()  # binary output\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, 3, 200, 200)\n",
        "        x = self.conv1(x)          # (batch, 32, 198, 198)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)           # (batch, 32, 99, 99)\n",
        "        x = torch.flatten(x, 1)    # (batch, 32*99*99)\n",
        "        x = self.fc1(x)            # (batch, 64)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)            # (batch, 1)\n",
        "        x = self.sigmoid(x)        # probability for class 1\n",
        "        return x"
      ],
      "metadata": {
        "id": "OK6COaEKCpBM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
        "\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "94u3Iu8ACrMl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "# 1) Define same size, channels-first, and normalization if you want\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),     # model expects 200x200 [web:35]\n",
        "    transforms.ToTensor(),             # -> (C, H, W), values in [0, 1] [web:36]\n",
        "    # Optional: add Normalize(...) here if you trained with it [web:39]\n",
        "])\n",
        "\n",
        "# 2) Load and transform image\n",
        "img = img.convert(\"RGB\")  # 3 channels [web:37]\n",
        "x = transform(img)            # shape (3, 200, 200)\n",
        "x = x.unsqueeze(0)            # shape (1, 3, 200, 200) add batch dim [web:35]"
      ],
      "metadata": {
        "id": "OJSwlo4wDjw9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()\n",
        "model.eval()                                                            # eval mode [web:37]\n",
        "\n",
        "with torch.no_grad():\n",
        "    y = model(x)              # shape (1, 1)\n",
        "    prob = y.item()           # scalar probability for class 1\n",
        "\n",
        "# For binary decision:\n",
        "pred = 1 if prob >= 0.5 else 0\n",
        "print(\"prob:\", prob, \"pred:\", pred)"
      ],
      "metadata": {
        "id": "X7sRELQVESxA",
        "outputId": "d477fa06-288a-4062-9a4c-73b9488eb3b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prob: 0.4977841079235077 pred: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "pip install udocker\n",
        "udocker --allow-root install"
      ],
      "metadata": {
        "id": "F7hNBwn4WzIY",
        "outputId": "a9641ed3-20ae-4860-ac15-af4f8da3c6cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting udocker\n",
            "  Downloading udocker-1.3.17-py2.py3-none-any.whl.metadata (37 kB)\n",
            "Downloading udocker-1.3.17-py2.py3-none-any.whl (119 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/119.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.6/119.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: udocker\n",
            "Successfully installed udocker-1.3.17\n",
            "Info: creating repo: /root/.udocker\n",
            "Info: udocker command line interface 1.3.17\n",
            "Info: searching for udockertools >= 1.2.11\n",
            "Info: installing udockertools 1.2.11\n",
            "Info: installation of udockertools successful\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "repo = \"agrigorev/model-2025-hairstyle\"\n",
        "tag = \"v1\"\n",
        "\n",
        "# 获取 token\n",
        "auth_url = f\"https://auth.docker.io/token?service=registry.docker.io&scope=repository:{repo}:pull\"\n",
        "token = requests.get(auth_url).json()[\"token\"]\n",
        "\n",
        "# 获取 manifest\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {token}\",\n",
        "    \"Accept\": \"application/vnd.docker.distribution.manifest.v2+json\"\n",
        "}\n",
        "manifest_url = f\"https://registry-1.docker.io/v2/{repo}/manifests/{tag}\"\n",
        "manifest = requests.get(manifest_url, headers=headers).json()\n",
        "\n",
        "# 输出 digest\n",
        "digest = manifest[\"config\"][\"digest\"]\n",
        "print(\"Manifest digest:\", digest)\n",
        "\n",
        "# 计算镜像总大小\n",
        "total_size = sum(layer[\"size\"] for layer in manifest[\"layers\"])\n",
        "print(\"Total size (bytes):\", total_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYIgx_-qW39a",
        "outputId": "3d3dc59f-ccbb-40e9-f59c-20ff56f7d1b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manifest digest: sha256:4528ad1525d55b7b0c0872d6b7882b654162fcc05a013e455719ac0c0eb44ad3\n",
            "Total size (bytes): 268965283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Colab: 使用 ONNX 模型预测图片\n",
        "# ===============================\n",
        "\n",
        "# -------------------------------\n",
        "# 1. 安装 ONNX Runtime\n",
        "# -------------------------------\n",
        "!pip install onnxruntime pillow torchvision\n",
        "\n",
        "# -------------------------------\n",
        "# 2. 导入库\n",
        "# -------------------------------\n",
        "import onnxruntime as ort\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------------\n",
        "# 3. 配置路径\n",
        "# -------------------------------\n",
        "onnx_model_path = \"/content/hair_classifier_v1.onnx\"  # 你的 ONNX 模型\n",
        "input_image_path = \"/content/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"                  # 上传的图片\n",
        "output_image_path = \"/content/output.jpeg\"\n",
        "\n",
        "# -------------------------------\n",
        "# 4. 加载模型\n",
        "# -------------------------------\n",
        "session = ort.InferenceSession(onnx_model_path)\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "print(\"Model input:\", input_name)\n",
        "print(\"Model output:\", output_name)\n",
        "\n",
        "# -------------------------------\n",
        "# 5. 处理输入图片\n",
        "# -------------------------------\n",
        "img = Image.open(input_image_path).convert(\"RGB\")\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor(),                # 归一化到 [0,1]\n",
        "])\n",
        "img_tensor = transform(img).unsqueeze(0)  # batch dim\n",
        "img_numpy = img_tensor.numpy().astype(np.float32)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. 推理\n",
        "# -------------------------------\n",
        "outputs = session.run([output_name], {input_name: img_numpy})\n",
        "output = outputs[0]\n",
        "print(\"Raw model output:\", output)\n",
        "\n",
        "# -------------------------------\n",
        "# 7. 如果输出是图像，将其保存\n",
        "# -------------------------------\n",
        "if output.ndim == 4:  # batch, C, H, W\n",
        "    output_img = transforms.ToPILImage()(output.squeeze())\n",
        "    output_img.save(output_image_path)\n",
        "    output_img.show()"
      ],
      "metadata": {
        "id": "tzOOxAmakKPG",
        "outputId": "46769be3-7ee7-48e4-c507-3f0a162d4a9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.12/dist-packages (1.23.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.9.23)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.14.0)\n",
            "Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (75.2.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->torchvision) (3.0.3)\n",
            "Model input: input\n",
            "Model output: output\n",
            "Raw model output: [[2.0972447]]\n"
          ]
        }
      ]
    }
  ]
}